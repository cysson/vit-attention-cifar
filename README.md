# vit-attention-cifar
A PyTorch project combining ResNet, attention mechanisms and MobileViT for image classification on CIFAR-10
# ğŸ” åŸºäºæ³¨æ„åŠ›æœºåˆ¶ä¸ Transformer çš„å›¾åƒåˆ†ç±»æ¨¡å‹è®¾è®¡ä¸å¯¹æ¯”å®éªŒ

æœ¬é¡¹ç›®æ—¨åœ¨å¯¹æ¯”ä¸åŒç±»å‹çš„æ³¨æ„åŠ›æœºåˆ¶ï¼ˆSEã€CBAMã€ECAï¼‰ä¸èåˆ Transformer æ¨¡å—ï¼ˆMobileViTï¼‰å¯¹å›¾åƒåˆ†ç±»ä»»åŠ¡æ€§èƒ½çš„å½±å“ã€‚æˆ‘ä»¬åŸºäº ResNet18/50 æ¶æ„ï¼Œåœ¨ CIFAR-10 æ•°æ®é›†ä¸Šè¿›è¡Œäº†å¤šç»„æ¨¡å‹ç»“æ„å®éªŒã€‚

---

## ğŸ§± å®éªŒç»“æ„è®¾è®¡

æœ¬é¡¹ç›®æ”¯æŒä»¥ä¸‹æ¨¡å‹ç»“æ„ï¼š

| æ¨¡å‹åç§°          | æè¿°è¯´æ˜                                 |
| ----------------- | ---------------------------------------- |
| `resnet18`        | åŸºç¡€å·ç§¯æ®‹å·®ç½‘ç»œï¼ˆæµ…å±‚ï¼‰                 |
| `resnet50`        | æ·±å±‚æ®‹å·®ç½‘ç»œ                             |
| `resnet18 + SE`   | åŠ å…¥é€šé“æ³¨æ„åŠ›ï¼ˆSqueeze-and-Excitationï¼‰ |
| `resnet18 + CBAM` | é€šé“+ç©ºé—´æ³¨æ„åŠ›ï¼ˆCBAMï¼‰                  |
| `resnet18 + ECA`  | é«˜æ•ˆé€šé“æ³¨æ„åŠ›æ¨¡å—ï¼ˆECAï¼‰                |
| `mobilevit`       | å·ç§¯ + Transformer èåˆæ¨¡å—              |

æ‰€æœ‰æ¨¡å‹å‡é€šè¿‡ YAML æ–‡ä»¶é…ç½®ï¼Œè®­ç»ƒè½®æ•°ç»Ÿä¸€è®¾ç½®ä¸º 300ã€‚

---

## ğŸ§ª æ•°æ®é›†ä¸ç¯å¢ƒ

- æ•°æ®é›†ï¼šCIFAR-10ï¼ˆè‡ªåŠ¨ä¸‹è½½ï¼‰
- å›¾åƒå¤§å°ï¼š3Ã—32Ã—32
- åˆ†ç±»æ•°ï¼š10 ç±»
- å¼€å‘ç¯å¢ƒï¼š
  - Python 3.8+
  - PyTorch >= 1.10
  - CUDA æ”¯æŒï¼ˆå¯é€‰ï¼‰
  - `wandb`ï¼ˆå¯é€‰ï¼Œç”¨äºè®°å½•è®­ç»ƒè¿‡ç¨‹ï¼‰

---

## ğŸš€ è¿è¡Œæ–¹æ³•

### âœ… å•æ¨¡å‹è®­ç»ƒ

```bash
python main.py --config config/baseline/resnet18.yaml
```
---
### âœ… æ‰¹é‡å®éªŒè¿è¡Œ
```bash
chmod +x run.sh
./run.sh
```
---
### âœ… é…ç½®æ–‡ä»¶æ ·ä¾‹ï¼ˆconfig/baseline/resnet18_cbam.yamlï¼‰
```yaml
model: resnet18
dataset: CIFAR10
num_classes: 10
lr: 0.01
optimizer: Adam
batch_size: 128
epochs: 200
base_channels: 64
attention: CBAM
```
---

### é¡¹ç›®ç»“æ„
```text

â”œâ”€â”€ main.py                   # ä¸»è®­ç»ƒå…¥å£
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ resnet.py             # ResNet18/50 + attentionæ”¯æŒ
â”‚   â”œâ”€â”€ resnet_mobilevit.py   # MobileViTæ¨¡å—å®šä¹‰
â”‚   â””â”€â”€ attention.py          # SELayer / CBAM / ECA å®ç°
â”œâ”€â”€ config/
â”‚   â””â”€â”€ baseline/*.yaml       # å„æ¨¡å‹å¯¹åº”é…ç½®æ–‡ä»¶
â”œâ”€â”€ run.sh                    # æ‰¹é‡è¿è¡Œè„šæœ¬
â”œâ”€â”€ utils/
â”‚   â””â”€â”€ progress_bar.py       # ç®€æ˜“è®­ç»ƒè¿›åº¦æ¡
â””â”€â”€ logs/                     # æ¯æ¬¡è¿è¡Œæ—¥å¿—è¾“å‡º
```
---

### ğŸ“Š å®éªŒæŒ‡æ ‡è®°å½•å»ºè®®
æ¨¡å‹ç»“æ„	å‚æ•°é‡(M)	Top-1 å‡†ç¡®ç‡	æœ€ä¼˜ epoch
ResNet18	11M	84.95%	-
ResNet18 + SE	11.3M	90.3%	-
ResNet18 + CBAM	11.5M	92.62%	-
ResNet18 + ECA	11.2M	90.74%	-
ResNet50	23M	90.04%	-
MobileViTResNet	~13M	93.33%	-

---

### ğŸ“š å‚è€ƒæ–‡çŒ®
[1] He K, et al., "Deep Residual Learning for Image Recognition", CVPR 2016.

[2] Hu J, et al., "Squeeze-and-Excitation Networks", CVPR 2018.

[3] Woo S, et al., "CBAM: Convolutional Block Attention Module", ECCV 2018.

[4] Wang Q, et al., "ECA-Net", CVPR 2020.

[5] Mehta S, Rastegari M, "MobileViT", ICLR 2022.
